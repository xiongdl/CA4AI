# CA4AI
Awesome Materials on Topic "Computer Architecture for AI".

# Book
- 2024 Springer - Towards Heterogeneous Multi-core Systems-on-Chip for Edge Machine Learning.
  - Website: https://drive.google.com/file/d/1erxYYDDZk4vAGDIqe1unNvaAXiFi5r6L/view
- 2024 - Machine Learning System with TinyML. (Harvard University, CS249r)
  - Website: https://harvard-edge.github.io/cs249r_book/Machine-Learning-Systems.pdf
- 2020 SLCA - Efficient Processing of Deep Neural Networks.
- 2020 SLCA - Data Orchestration in Deep Learning Accelerators.

# Course
- 2024 Spring - Hardware for Machine Learning. (Berkeley EE290-2)
  - Website: https://inst.eecs.berkeley.edu/~ee290-2/sp24/

# Tutorial
- 2019 ISCA - Hardware Architectures for Deep Neural Networks. (MIT, NVIDIA)
  - Website: http://eyeriss.mit.edu/tutorial.html

# Insight
- 2024 ISSCC - Semiconductor Industry: Present & Future. (TSMC)
  - Takeaways:
    - Continued advanced technology scaling: new device architecture (CFET), low dimensional channel materials.
    - Essential design-technology co-optimization (DTCO): extract maximum values by tailoring technology definition (standard logic cell, SRAM, etc).
    - Essential system-technology co-optimization (STCO): logic integration (2.5D + 3D integration), memory bandwidth (memory + logic), specially for power delivery (voltage regulator integration), specially for interconnect speed (OE on substrate).
- 2024 ISSCC - Computing in the Era of Generative AI. (NVIDIA)
  - Takeaways:
    - Being an early adopter is hard and uncomfortable but I encourge you to believe it can pay off.
    - The most important lesson is not expect immediate miracles. You have to be persistent, especially if you're trying a new era.
    - Instead, believe that AI will fundamentally transform the semiconductor industry and your business.
  

# Survey
- Commercial AI Accelerators Survey from MIT Lincoln Laboratory Supercomputing Center.
  - 2023 HPEC - Lincoln AI Computing Survey (LAICS) Update.
  - 2022 HPEC - AI and ML Accelerator Survey and Trends.
  - 2021 HPEC - AI Accelerator Survey and Trends.
  - 2020 HPEC - Survey of Machine Learning Accelerators.
  - 2019 HPEC - Survey and Benchmarking of Machine Learning Accelerators.
- 2022 TCSI - Reconfigurability, Why It Matters in AI Tasks Processing: A Survey of Reconfigurable AI Chips. (Tsinghua University)
- 2020 JPROC - Model Compression and Hardware Acceleration for Neural Networks: A Comprehensive Survey. (Tsinghua University)
- 2017 JPROC - Efficient Processing of Deep Neural Networks: A Tutorial and Survey. (MIT)
- Neural Network Accelerator Comparison from NICS EFC Lab of Tsinghua University.
  - Website: https://nicsefc.ee.tsinghua.edu.cn/projects/neural-network-accelerator/
- Computation Used to Train Notable Artificial Intelligence Systems
  - Website: https://ourworldindata.org/grapher/artificial-intelligence-training-computation 

# Paper Reading
- The review questions guide you through the paper reading process. (cite from EE290-2 slides)
  - What are the **motivations** for this work?
  - What is the **proposed solution**?
  - What is the work's **evaluation** of the proposed solution?
  - What is your **analysis** of the identified problem, idea and evaluation?
  - What are **future directions** for this research?
  - What **questions** are you left with?
  
# Conference
### 2024 ISSCC
- AMD Instinct MI300 Series Modular Chiplet Package - HPC and AI Accelerator for Exa-Class Systems.(AMD)
  - Direction: Hardware-Chip
  - Keywords: Chiplet, Advanced Packing
  - Contributions:
    - Two new chiplet types are introduced in MI300, the input/output die (IOD) and the accelerator complex die (XCD).
    - MI300 is not just the first AMD multiple die hybrid bonded architecture but also the first AMD hybrid bonded 3D+2.5D Architecture.

# Transaction

